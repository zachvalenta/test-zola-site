https://x.com/barbell_fi
https://simonwillison.net/2023/Dec/31/ai-in-2023/

# 1Mx

https://simonwillison.net/2024/Oct/21/claude-artifacts/

* supercharged smart young people https://www.youtube.com/watch?v=OmiwV8kUz2E https://www.bitecode.dev/p/what-if-ai-eventually-make-programmers

on a personal level, it will be an engine for inequality. the concept of a 10x dev was probably already an understatement. the best are 100x or 1000x. AI will make that higher and create more of them. will raise the level of x as well.

# teaching us to prompt

* teaching people how to ask better questions https://paulgraham.com/writes.html
> PG might be right for most people but I estimate that LLMs will actually make their users *better* at writing clearly. Will take the Stack Overflow ethos to a wider audience. https://stackoverflow.com/help/how-to-ask
* Stack Overflow won in losing https://x.com/Altimor/status/1853893158368928124

# what i use it for

* summarization, taxonomization
* tool recs https://chatgpt.com/share/673fae40-6554-8004-b1bf-9c664399ae59
* big picture questions
* learning new concepts (regression, dimensional analysis) https://github.com/zachvalenta/apple-models-data-analysis

> that little repo took me ~30 minutes total work, spanning initial idea to completion. that * ideas in a day * days in a year has been a massive delta for me. ++ I feel like my ability to use AI tooling well growing exponentially. diff btw today vs. a month ago night and day.

# casualties

* punishes languages with bad semantics e.g. SQL CTE's https://talkpython.fm/episodes/show/481/python-opinions-and-zeitgeist-with-hynek
* Stack Overflow
* Google

# impact on sw dev

https://registerspill.thorstenball.com/p/they-all-use-it https://news.ycombinator.com/item?id=41930767
makes mistakes all the time but that's why we're here! re: `direnv` https://chatgpt.com/c/673f8c16-e090-8004-bdc8-564bbfeb33d5
> LLMs are good at explaining code. Give it code in a language you don't understand and it will explain it with 90% accuracy. https://katherinemichel.github.io/portfolio/pycon-us-2024-recap.html#simon-willison-keynote

https://news.ycombinator.com/item?id=42095434 there's a fair amount of pushback as well. i align with the first comment to this guy. decent amount of pushback seems like: "im a real man, my editor is emacs, i have strong opinions about c99 vs. rust, LLMs are for homos who write $DYNAMICALLY_TYPED_LANGUAGE_HERE" + people that are bad at writing prompts. essentially, LLMs reward the type of person who could write a good question on Stack Overflow or otherwise teaches them how to do so (if they are willing to learn) https://stackoverflow.com/help/mcve - to Josh/Kurt 24.11.15

this sounds hyperbolic, but i think AI is going to be akin to the dawn of relational databases in the 80s when it comes to the software industry. re: orgs.

take databases: "no you dont need all those people punching up figures. you can replace all your accountants and secretaries with cobol!". -> do we have more or less jobs centered around the production/maintenance/whatever of business data in 2024 than we did in 1974? it would seem to me a great deal more.

dunno if this will hold for number of devs, but feel >=50% that there will be a fuck ton more code written in 5 years than today.

bigger economy = longer tail

> The amount of money flowing through capitalism would astound you. The number and variety of firms participating in the economy would astound you. We don't see most of it every day for the same reason abstractions protect us from having to care about metallurgy while programming. - McKenzie https://twitter.com/patio11/status/936629780719419392

more code = longer tail (like Cobol-to-Java AIs) https://bloop.ai/
